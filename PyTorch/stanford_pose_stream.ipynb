{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Our libraries\n",
    "from train import train_model\n",
    "from model_utils import *\n",
    "from predict_utils import *\n",
    "from vis_utils import *\n",
    "from apmeter import *\n",
    "from train_valid_split import *\n",
    "\n",
    "# some initial setup\n",
    "np.set_printoptions(precision=2)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(trn_hist, val_hist, loss_acc):\n",
    "    plt.plot(trn_hist, label='Training ' + loss_acc)\n",
    "    plt.plot(val_hist, label='Validation ' + loss_acc)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(loss_acc)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_bn(m):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if (cuda_available and use_gpu) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"F:/MyArticel/DTASET/MY_SPLIT_DATASETssss/stanford40/stanford40_mak_pose/\"\n",
    "\n",
    "sz = 224\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dir = f'{DATA_DIR}train'\n",
    "val_dir = f'{DATA_DIR}valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(trn_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_fnames = glob.glob(f'{trn_dir}/*/*.png')\n",
    "trn_fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "train_ds = datasets.ImageFolder(trn_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_ds.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data augmentation and normalization for training \n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((sz, sz)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.01),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Just normalization for validation\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((sz, sz)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(f'{DATA_DIR}train', train_transforms)\n",
    "#valid_ds = datasets.ImageFolder(f'{DATA_DIR}valid', valid_transforms)\n",
    "\n",
    "train_ds, valid_ds = train_valid_split(train_ds, 10)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_ds_sz = len(train_ds)\n",
    "valid_ds_sz = len(valid_ds)\n",
    "\n",
    "print('Train size: {}\\nValid size: {} ({:.2f})'.format(train_ds_sz, valid_ds_sz, valid_ds_sz/(train_ds_sz + valid_ds_sz)))\n",
    "\n",
    "class_names = train_ds.mother.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len (train_ds), len (valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, \n",
    "                                       shuffle=True, num_workers=4)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=batch_size, \n",
    "                                       shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,targets =  next(iter(train_dl))\n",
    "out = torchvision.utils.make_grid(inputs, padding=3)\n",
    "plt.figure(figsize=(16, 12))\n",
    "imshow(out, title='random image from training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# load pre-trained ResNet50\n",
    "model = load_pretrained_resnet50(model_path=None, num_classes=7)\n",
    "model.apply(freeze_bn)\n",
    "\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0003, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0002)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.95)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "model, trn_loss_hist, val_loss_hist, trn_acc_hist, val_acc_hist = train_model(model, train_dl, valid_dl, criterion, optimizer, scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_acc = 'Loss'\n",
    "plot_loss(trn_loss_hist, val_loss_hist, loss_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_acc = 'Accuracy'\n",
    "plot_loss(trn_acc_hist, val_acc_hist, loss_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.require_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0003, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, trn_loss_hist1, val_loss_hist1, trn_acc_hist1, val_acc_hist1 = train_model(model, train_dl, valid_dl, criterion, optimizer, scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loss_hist.extend(trn_loss_hist1)\n",
    "val_loss_hist.extend(val_loss_hist1)\n",
    "trn_acc_hist.extend(trn_acc_hist1)\n",
    "val_acc_hist.extend(val_acc_hist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_acc = 'Loss'\n",
    "plot_loss(trn_loss_hist, val_loss_hist, loss_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_acc = 'Accuracy'\n",
    "plot_loss(trn_acc_hist, val_acc_hist, loss_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acuracy on validation data\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # for batch normalization layers\n",
    "    corrects = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = to_var(inputs, True), to_var(targets, True)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        corrects += (preds == targets.data).sum()\n",
    "    \n",
    "    print('accuracy: {:.2f}'.format(100. * corrects / len(dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mAP\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "def calculate_model_mAP(model, dataloader):\n",
    "    mAP = APMeter()\n",
    "    model.eval()  # for batch normalization layers\n",
    "    corrects = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = to_var(inputs, True), to_var(targets, True)\n",
    "        outputs = model(inputs)\n",
    "        outputs = m(outputs)\n",
    "        targets.resize_(targets.size(0), 1)\n",
    "        targets = Variable(targets)\n",
    "        \n",
    "        one_hot = torch.cuda.FloatTensor(targets.size(0), outputs.size(1)).zero_()\n",
    "        one_hot.scatter_(1, targets.data, 1)\n",
    "        one_hot = Variable(one_hot)\n",
    "        mAP.add(outputs,one_hot)\n",
    "\n",
    "        #print(outputs.data)\n",
    "    \n",
    "    for i, value in enumerate(mAP.value()):\n",
    "        print(train_ds.classes[i], ' AP: {:.2f}'.format(100. * value))\n",
    "    print('mAP: {:.2f}'.format(100. * mAP.value().sum() / mAP.value().size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "y_pred, y_true = predict_class(model, valid_dl)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm, train_ds.classes, normalize=True, figsize=(12,12 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the sizes of the images\n",
    "\n",
    "fnames = glob.glob(f'{trn_dir}/*/*.png')\n",
    "sizes = [Image.open(f).size for f in fnames]\n",
    "\n",
    "hs, ws = list(zip(*sizes))\n",
    "\n",
    "plt.figure(figsize=(12., 4.))\n",
    "plt.hist(hs)\n",
    "plt.hist(ws);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model, valid_dl, num_images=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing\n",
    "\n",
    "class_names = train_ds.classes\n",
    "test_dir = f'{DATA_DIR}\\\\test'\n",
    "test_ds = datasets.ImageFolder(test_dir,valid_transforms)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dataloder\n",
    "\n",
    "test_dl =  torch.utils.data.DataLoader(test_ds,batch_size= batch_size, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_names, y = predict_class_names(model, test_dl, class_names)\n",
    "\n",
    "test_fnames= glob.glob(f'{test_dir}/*/*.png')\n",
    "len(test_fnames), test_fnames [:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fnames_len= len(test_fnames)\n",
    "for i in range(test_fnames_len):\n",
    "    test_fnames[i] = os.path.basename(test_fnames[i])\n",
    "    \n",
    "    len(test_fnames), test_fnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = np.stack([test_fnames, pred_class_names], axis=1)\n",
    "len(pred_result), pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_model_mAP(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_errors(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "y_pred, y_true = predict_class(model, test_dl)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm, train_ds.classes, normalize=True, figsize=(12,12 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
